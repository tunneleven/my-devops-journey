# EC2 Instance Families

> "Match the right instance to your workload bottleneck â€” CPU, RAM, Storage, or GPU."

## What Are Instance Families?

```
âœ… Instance families group EC2 instances by optimization type
âœ… Each family is designed for specific workload patterns
âœ… Choosing the right family = better performance + lower cost
âœ… CLF-C02 exam loves testing "which family for which scenario"
```

---

## Instance Naming Convention

```
    m5.2xlarge
    â”‚ â”‚  â”‚
    â”‚ â”‚  â””â”€â”€ SIZE: nano < micro < small < medium < large < xlarge < 2xlarge...
    â”‚ â”‚           (More vCPUs and RAM as size increases)
    â”‚ â”‚
    â”‚ â””â”€â”€â”€â”€â”€ GENERATION: Higher number = newer, better efficiency
    â”‚                    (m5 â†’ m6 â†’ m7 = progressively better)
    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€ FAMILY: Letter indicating optimization type
                     M = General, C = Compute, R = Memory, etc.
```

### Additional Naming Suffixes

| Suffix | Meaning | Example |
|--------|---------|---------|
| **g** | AWS Graviton (ARM) | m7g.large |
| **a** | AMD processor | m6a.xlarge |
| **i** | Intel processor | m6i.large |
| **n** | Network optimized | m5n.large |
| **d** | Local NVMe storage | m5d.large |
| **z** | High frequency | m5zn.large |

---

## The 5 Instance Family Categories

```
EC2 INSTANCE FAMILIES
â”œâ”€â”€ ðŸŒ GENERAL PURPOSE (M, T, Mac)
â”‚   â””â”€â”€ Balanced CPU/Memory/Network
â”‚
â”œâ”€â”€ âš¡ COMPUTE OPTIMIZED (C)
â”‚   â””â”€â”€ High CPU, lower memory ratio
â”‚
â”œâ”€â”€ ðŸ§  MEMORY OPTIMIZED (R, X, z, u-)
â”‚   â””â”€â”€ High RAM, for in-memory workloads
â”‚
â”œâ”€â”€ ðŸ’¾ STORAGE OPTIMIZED (I, D, H)
â”‚   â””â”€â”€ High IOPS, fast local storage
â”‚
â””â”€â”€ ðŸŽ® ACCELERATED COMPUTING (P, G, Trn, Inf, F)
    â””â”€â”€ GPU/TPU/FPGA for ML and graphics
```

---

## ðŸŒ General Purpose (M, T, Mac)

> **Memory Hook**: "**M**iddle ground, **T**urbo bursts"

### Family Comparison

| Family | Key Feature | Use Case | Exam Keyword |
|--------|-------------|----------|--------------|
| **M** | Balanced (50/50 CPU/RAM) | Web servers, small DBs, app servers | "general purpose", "balanced" |
| **T** | Burstable (CPU credits) | Dev/test, low-traffic websites | "variable traffic", "cost-effective" |
| **Mac** | Apple hardware | iOS/macOS development, Xcode | "macOS", "iOS app" |

### Deep Dive: T-Series (Burstable)

```
T-SERIES CPU CREDIT SYSTEM

    Baseline CPU: 20%
    â”œâ”€â”€ Normal use: Accumulate credits
    â”œâ”€â”€ Burst use: Spend credits (up to 100% CPU)
    â””â”€â”€ Credits depleted: Throttled to baseline
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ CPU                                    â”‚
    â”‚  â–²                                     â”‚
    â”‚  â”‚    â–ˆâ–ˆâ–ˆâ–ˆ                             â”‚
    â”‚  â”‚   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            â”‚
    â”‚ 20%â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Baseline          â”‚
    â”‚  â”‚                                     â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Time â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    T3 Modes:
    â”œâ”€â”€ Standard Mode: Pay for extra burst (default)
    â””â”€â”€ Unlimited Mode: Always burst, pay per vCPU-hour
```

### Real-World Examples

| Scenario | Family | Why |
|----------|--------|-----|
| WordPress blog (low traffic) | **T3.micro** | Bursty traffic, cost-effective |
| Corporate web app | **M6i.large** | Consistent load, balanced needs |
| iOS CI/CD pipeline | **Mac** | Requires macOS for Xcode builds |

---

## âš¡ Compute Optimized (C)

> **Memory Hook**: "**C**PU cruncher"

### When to Use

```
COMPUTE OPTIMIZED = HIGH CPU : LOW MEMORY RATIO

Perfect for:
â”œâ”€â”€ ðŸ”¬ Scientific modeling
â”œâ”€â”€ ðŸŽ® Gaming servers (CPU-bound)
â”œâ”€â”€ ðŸ“¹ Video encoding/transcoding
â”œâ”€â”€ ðŸ“Š Batch processing
â”œâ”€â”€ ðŸŒ High-performance web servers
â””â”€â”€ ðŸ¤– ML inference (CPU-based)
```

### Comparison with General Purpose

| Aspect | M6i.large | C6i.large |
|--------|-----------|-----------|
| vCPUs | 2 | 2 |
| Memory | 8 GB | 4 GB |
| Ratio | 1:4 (balanced) | 1:2 (CPU-focused) |
| Best For | General apps | CPU-intensive |

### Real-World Examples

| Scenario | Instance | Why |
|----------|----------|-----|
| Apache Spark batch jobs | **C6i.2xlarge** | CPU-intensive data processing |
| Video transcoding | **C5.4xlarge** | High clock speed for encoding |
| Game server (Minecraft) | **C5.large** | Low latency, CPU-bound |

---

## ðŸ§  Memory Optimized (R, X, z, High Memory)

> **Memory Hook**: "**R**AM-focused, e**X**tra memory"

### Family Breakdown

| Family | RAM Capacity | Use Case |
|--------|--------------|----------|
| **R** | High (up to 768 GB) | In-memory DBs (Redis, Memcached) |
| **X** | Extra High (up to 4 TB) | SAP HANA, large in-memory analytics |
| **z** | High + compute | Memory-bound + high frequency |
| **u-** (High Memory) | Extreme (up to 24 TB) | Massive in-memory workloads |

### Memory-to-CPU Ratios

```
MEMORY RATIOS BY FAMILY

General Purpose (M):     1 vCPU : 4 GB RAM
Memory Optimized (R):    1 vCPU : 8 GB RAM  â† 2x memory!
Memory Optimized (X):    1 vCPU : 16 GB RAM â† 4x memory!

Example:
â”œâ”€â”€ m6i.xlarge:  4 vCPU,  16 GB RAM
â”œâ”€â”€ r6i.xlarge:  4 vCPU,  32 GB RAM  â† Same vCPU, 2x RAM
â””â”€â”€ x2idn.xlarge: 4 vCPU, 64 GB RAM  â† Same vCPU, 4x RAM
```

### Real-World Examples

| Scenario | Instance | Why |
|----------|----------|-----|
| Redis cache cluster | **R6i.large** | In-memory caching |
| SAP HANA database | **X2idn.xlarge** | Massive in-memory DB |
| Real-time analytics | **R5.2xlarge** | Fast data processing in RAM |

---

## ðŸ’¾ Storage Optimized (I, D, H)

> **Memory Hook**: "**I**ntense **I**/O"

### Family Breakdown

| Family | Storage Type | Best For |
|--------|--------------|----------|
| **I** | NVMe SSD (high IOPS) | NoSQL (Cassandra, MongoDB), transactional DBs |
| **D** | Dense HDD (high capacity) | Data lakes, Hadoop, HDFS |
| **H** | HDD + HPC | Sequential I/O, MapReduce, log processing |

### When to Use Each

```
STORAGE OPTIMIZED DECISION TREE

Need high random IOPS?
â”œâ”€â”€ YES â†’ I-series (SSD)
â”‚   â””â”€â”€ Use for: MongoDB, Cassandra, real-time analytics
â”‚
â””â”€â”€ NO â†’ Need high sequential throughput?
    â”œâ”€â”€ YES â†’ D-series or H-series (HDD)
    â”‚   â””â”€â”€ Use for: Hadoop, data warehousing, HDFS
    â””â”€â”€ NO â†’ Consider EBS instead
```

### Real-World Examples

| Scenario | Instance | Why |
|----------|----------|-----|
| MongoDB cluster | **I3.2xlarge** | High IOPS for random reads/writes |
| Hadoop data lake | **D3.xlarge** | Dense HDD for batch processing |
| Log aggregation (ELK) | **I4i.large** | Fast indexing with NVMe |

---

## ðŸŽ® Accelerated Computing (P, G, Trn, Inf, F)

> **Memory Hook**: "**G**PU power for ML and **G**raphics"

### Family Breakdown

| Family | Hardware | Use Case |
|--------|----------|----------|
| **P** | NVIDIA GPUs (A100, V100) | Deep learning training, HPC |
| **G** | NVIDIA GPUs (T4, A10G) | Graphics, game streaming, video |
| **Trn** | AWS Trainium | Distributed ML training (cost-effective) |
| **Inf** | AWS Inferentia | ML inference (low latency) |
| **F** | FPGAs | Custom hardware acceleration |
| **DL** | Deep Learning AMI optimized | AI/ML with frameworks |
| **VT** | Video transcoding | Media processing |

### Training vs Inference

```
ML WORKFLOW â†’ INSTANCE SELECTION

                    TRAINING                    INFERENCE
                (Building model)            (Using model)
                      â”‚                           â”‚
                      â–¼                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   P5, Trn1      â”‚        â”‚   Inf2, G5      â”‚
            â”‚   (Heavy GPU)   â”‚        â”‚   (Optimized)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
               Hours/Days                   Milliseconds
               High cost                    Low cost
```

### Real-World Examples

| Scenario | Instance | Why |
|----------|----------|-----|
| Training GPT model | **P5.48xlarge** | NVIDIA H100 GPUs |
| Real-time ML inference | **Inf2.xlarge** | Low latency, cost-effective |
| Cloud gaming | **G5.xlarge** | NVIDIA A10G for graphics |
| Video streaming service | **VT1.3xlarge** | Hardware video transcoding |

---

## ðŸ”¥ Real Exam Questions (With Answers)

### Question 1
> A company needs to run a web application that experiences variable traffic throughout the day. During peak hours, CPU usage can spike to 80%, but most of the time it stays at 20%. Which instance type is MOST cost-effective?

**Answer: T3 (Burstable)**
- Variable traffic = bursty pattern
- Low baseline + occasional spikes = perfect for T-series CPU credits
- More cost-effective than M-series for this pattern

---

### Question 2
> A data analytics company is running Apache Spark jobs that are CPU-bound. The jobs complete slowly on current general-purpose instances. Which instance family should they migrate to?

**Answer: C (Compute Optimized)**
- "CPU-bound" = Compute Optimized
- Spark batch processing = high CPU requirement
- C-series has higher CPU-to-memory ratio

---

### Question 3
> A company runs an in-memory Redis cache that requires 128 GB of RAM. The cache is consistently hitting memory limits. Which instance family is MOST appropriate?

**Answer: R (Memory Optimized)**
- "In-memory cache" = Memory Optimized
- "Hitting memory limits" = need more RAM
- R-series provides 8 GB RAM per vCPU (vs 4 GB for M-series)

---

### Question 4
> A gaming company needs to train a deep learning model using GPU acceleration. The training is expected to take several days. Which instance family should they use?

**Answer: P (Accelerated Computing - Training)**
- "Deep learning training" = P-series
- "GPU acceleration" = NVIDIA GPUs
- P-series has most powerful GPUs for training

---

### Question 5
> A company runs a NoSQL database (Cassandra) that requires high disk IOPS for random read/write operations. Which instance family is MOST suited?

**Answer: I (Storage Optimized)**
- "High disk IOPS" = Storage Optimized
- "NoSQL (Cassandra)" = I-series SSD
- "Random read/write" = NVMe SSD performance

---

### Question 6
> A startup wants to deploy a machine learning model for real-time inference with the lowest latency possible. Which AWS chip should they consider?

**Answer: Inf (AWS Inferentia)**
- "Real-time inference" = Inferentia
- "Lowest latency" = AWS-designed inference chip
- Inf2 is optimized for production ML inference

---

### Question 7
> A company running a balanced web application can't decide between M and T series. Traffic is steady with no spikes. Which should they choose?

**Answer: M (General Purpose)**
- "Steady traffic, no spikes" = no need for burstable
- T-series is for variable workloads
- M-series provides consistent performance

---

## ðŸŽ¯ Exam Strategy Cheat Sheet

```
KEYWORD â†’ INSTANCE FAMILY MATCHER

"balanced, general purpose, web server"          â†’ M (General Purpose)
"dev/test, low traffic, variable, burst"         â†’ T (Burstable)
"CPU-intensive, batch, HPC, scientific"          â†’ C (Compute Optimized)
"in-memory, cache, Redis, SAP HANA"              â†’ R/X (Memory Optimized)
"high IOPS, NoSQL, Cassandra, MongoDB"           â†’ I (Storage Optimized)
"Hadoop, data lake, HDFS, big data"              â†’ D/H (Storage Optimized)
"ML training, deep learning, GPU"                â†’ P/Trn (Accelerated)
"ML inference, real-time prediction"             â†’ Inf (Accelerated)
"graphics, gaming, video streaming"              â†’ G (Accelerated)
"iOS, macOS, Xcode"                              â†’ Mac
```

---

## Summary

| Family | Memory Hook | Best For |
|--------|-------------|----------|
| **T** | **T**urbo bursts | Variable traffic, dev/test |
| **M** | **M**iddle ground | Balanced workloads |
| **C** | **C**PU cruncher | Compute-intensive tasks |
| **R** | **R**AM focused | In-memory databases |
| **X** | e**X**tra memory | Large in-memory (SAP HANA) |
| **I** | **I**ntense IOPS | NoSQL, transactional DBs |
| **D/H** | **D**ense storage | Data lakes, Hadoop |
| **P** | Deep learning **P**ower | ML training |
| **G** | **G**raphics | Gaming, video |
| **Trn** | AWS **Tr**ainium | Cost-effective ML training |
| **Inf** | **Inf**erence | ML serving, low latency |

---

## ðŸ”— Related Topics

- [EC2 Fundamentals](ec2.md) - Complete EC2 overview
- [EC2 Pricing Models](ec2.md#pricing-models) - Cost optimization
- [Auto Scaling](auto-scaling.md) - Scaling instance families
